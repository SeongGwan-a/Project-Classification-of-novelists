{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glove.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongGwan-a/Project-Classification-of-novelists/blob/main/RNN/glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHC-Vbo2g5p1"
      },
      "source": [
        "# 필요한 모듈\n",
        "\n",
        "from matplotlib import rcParams, pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkZnFkBQ1zl-"
      },
      "source": [
        "# 데이터 로드\n",
        "\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/소설작가분류/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/소설작가분류/test_x.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2S-fQyahp98",
        "outputId": "6601a5a6-b567-4373-8660-676a3be579eb"
      },
      "source": [
        "# 결측값 확인\n",
        "\n",
        "train.info(), test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 54879 entries, 0 to 54878\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   index   54879 non-null  int64 \n",
            " 1   text    54879 non-null  object\n",
            " 2   author  54879 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.3+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19617 entries, 0 to 19616\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   index   19617 non-null  int64 \n",
            " 1   text    19617 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 306.6+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iwUUygTt3sL"
      },
      "source": [
        "train.replace(\"\", float(\"NaN\"), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_wGtTLHt7q4",
        "outputId": "7ba52b3b-3ffd-402a-a196-276d94565936"
      },
      "source": [
        "# 결측값 확인\n",
        "\n",
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 54879 entries, 0 to 54878\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   index   54879 non-null  int64 \n",
            " 1   text    54879 non-null  object\n",
            " 2   author  54879 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXWFniwShyWG",
        "outputId": "9815d369-e8be-4f7c-de7f-fdb96a5f0980"
      },
      "source": [
        "# 중복값 확인\n",
        "\n",
        "train['text'].nunique(), test['text'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54744, 19606)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33vA7Wt-iC-D"
      },
      "source": [
        "# train data에서 135개 중복값 제거 (54879 - 54744 = 135)\n",
        "\n",
        "train_clean = train.drop_duplicates(subset=['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqR_WQJhhadl"
      },
      "source": [
        "# 부호와 불용어 제거 함수\n",
        "\n",
        "'''def alpha_num(text):\n",
        "    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stopwords:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "\n",
        "\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n",
        "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
        "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
        "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
        "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
        "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
        "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
        "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
        "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
        "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
        "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopword2 = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjsIc49fhTH6"
      },
      "source": [
        "# 소문자 변환\n",
        "\n",
        "train_clean['text'] = train_clean['text'].str.lower()\n",
        "test['text'] = test['text'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52QfWapHyGYF"
      },
      "source": [
        "X_data = train_clean['text'].values\n",
        "X_test = test['text'].values\n",
        "y_data = train_clean['author'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuvzoGTOL1gB",
        "outputId": "434d0a7a-29da-4251-9515-76da3f0f63b4"
      },
      "source": [
        "X_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54744,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AZ0LkLTLGJO"
      },
      "source": [
        "vocab_size = 42330"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iZ85UQeyVmD"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(X_data)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCiJoGGdyn4Y"
      },
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(X_data)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18UIyVm6LsQ6",
        "outputId": "f6d98243-b2e1-4de9-d3a5-b6750d454bd4"
      },
      "source": [
        "len(train_sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54744"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQghBq9W2e7a",
        "outputId": "f5d92c2c-2277-4635-bc08-add06863c1a8"
      },
      "source": [
        "max_len=max(len(l) for l in train_sequences)\n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWk0HxpmyubQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77421744-fe71-40b5-9199-c560b427356d"
      },
      "source": [
        "trn = pad_sequences(train_sequences, maxlen = max_len, padding='post')\n",
        "tst = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "print(trn.shape, tst.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54744, 473) (19617, 473)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LqS4Fo3zRn5"
      },
      "source": [
        "glove = open('/content/drive/MyDrive/소설작가분류/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "w2v = open('/content/drive/MyDrive/소설작가분류/GoogleNews-vectors-negative300.bin', encoding=\"utf8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8nBvPE80x09",
        "outputId": "7dcfa14b-6111-496f-f73f-78db42a3f734"
      },
      "source": [
        "glove_dict = dict()\n",
        "\n",
        "glove = open('/content/drive/MyDrive/소설작가분류/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32') # 100개의 값을 가지는 array로 변환\n",
        "    glove_dict[word] = word_vector_arr\n",
        "glove.close()\n",
        "print('%s개의 Embedding vector가 있습니다.' % len(glove_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000개의 Embedding vector가 있습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGSjVl6P1nP8"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "# 단어 집합 크기의 행과 100개의 열을 가지는 행렬 생성. 값은 전부 0으로 채워진다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hKQQlne2CZx"
      },
      "source": [
        "for word, i in word_index.items(): # 훈련 데이터의 단어 집합에서 단어를 1개씩 꺼내온다.\n",
        "    temp = glove_dict.get(word) # 단어(key) 해당되는 임베딩 벡터의 100개의 값(value)를 임시 변수에 저장\n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp # 임시 변수의 값을 단어와 맵핑되는 인덱스의 행에 삽입"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na1lz71k21Ap"
      },
      "source": [
        "'''model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfHzCp-o-ZY1"
      },
      "source": [
        "target_col = 'author'\n",
        "n_fold = 5\n",
        "n_class = 5\n",
        "seed = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRtvtI4u2Ly_"
      },
      "source": [
        "'''from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPT7Ebja-JsT"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VSUxx7h2S96"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
        "        Bidirectional(LSTM(64, return_sequences=True)),\n",
        "        Bidirectional(LSTM(64)),\n",
        "        Dense(n_class, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=.01))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgJO1jIs8KDC",
        "outputId": "1e8bf316-b723-45d3-aba2-c392695814e0"
      },
      "source": [
        "p_val = np.zeros((trn.shape[0], n_class))\n",
        "p_tst = np.zeros((tst.shape[0], n_class))\n",
        "\n",
        "for i, (i_trn, i_val) in enumerate(cv.split(trn, y_data), 1):\n",
        "    print(f'training model for CV #{i}')\n",
        "    clf = get_model()\n",
        "    \n",
        "    es = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3,\n",
        "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "    clf.fit(trn[i_trn], \n",
        "            to_categorical(y_data[i_trn]),\n",
        "            validation_data=(trn[i_val], to_categorical(y_data[i_val])),\n",
        "            epochs=10,\n",
        "            batch_size=512,\n",
        "            callbacks=[es])\n",
        "    p_val[i_val, :] = clf.predict(trn[i_val])\n",
        "    p_tst += clf.predict(tst) / n_fold"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model for CV #1\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 791s 9s/step - loss: 1.2614 - val_loss: 1.0421\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 779s 9s/step - loss: 0.9363 - val_loss: 0.8920\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 776s 9s/step - loss: 0.7847 - val_loss: 0.8006\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 778s 9s/step - loss: 0.6769 - val_loss: 0.7408\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 782s 9s/step - loss: 0.5930 - val_loss: 0.7402\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 777s 9s/step - loss: 0.5226 - val_loss: 0.7253\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 780s 9s/step - loss: 0.4459 - val_loss: 0.7615\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 777s 9s/step - loss: 0.3904 - val_loss: 0.8025\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.3422Restoring model weights from the end of the best epoch.\n",
            "86/86 [==============================] - 781s 9s/step - loss: 0.3422 - val_loss: 0.8322\n",
            "Epoch 00009: early stopping\n",
            "training model for CV #2\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 793s 9s/step - loss: 1.3113 - val_loss: 1.0206\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 784s 9s/step - loss: 0.9466 - val_loss: 0.9179\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 781s 9s/step - loss: 0.8470 - val_loss: 0.8080\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 784s 9s/step - loss: 0.7069 - val_loss: 0.7402\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 789s 9s/step - loss: 0.6127 - val_loss: 0.7092\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 784s 9s/step - loss: 0.5361 - val_loss: 0.7230\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 782s 9s/step - loss: 0.4776 - val_loss: 0.7218\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.4188Restoring model weights from the end of the best epoch.\n",
            "86/86 [==============================] - 782s 9s/step - loss: 0.4188 - val_loss: 0.7652\n",
            "Epoch 00008: early stopping\n",
            "training model for CV #3\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 804s 9s/step - loss: 1.3438 - val_loss: 1.1203\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 819s 10s/step - loss: 0.9594 - val_loss: 0.8990\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 812s 9s/step - loss: 0.7878 - val_loss: 0.7773\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 798s 9s/step - loss: 0.6765 - val_loss: 0.7436\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 800s 9s/step - loss: 0.5888 - val_loss: 0.7194\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 788s 9s/step - loss: 0.5104 - val_loss: 0.7150\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 796s 9s/step - loss: 0.4458 - val_loss: 0.7359\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 800s 9s/step - loss: 0.3787 - val_loss: 0.7998\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.3376Restoring model weights from the end of the best epoch.\n",
            "86/86 [==============================] - 805s 9s/step - loss: 0.3376 - val_loss: 0.8225\n",
            "Epoch 00009: early stopping\n",
            "training model for CV #4\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 791s 9s/step - loss: 1.3276 - val_loss: 1.1369\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 798s 9s/step - loss: 0.9608 - val_loss: 0.8819\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 797s 9s/step - loss: 0.8072 - val_loss: 0.7746\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 819s 10s/step - loss: 0.7874 - val_loss: 0.8887\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 827s 10s/step - loss: 0.7317 - val_loss: 0.7499\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 807s 9s/step - loss: 0.6137 - val_loss: 0.7246\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 806s 9s/step - loss: 0.5393 - val_loss: 0.7340\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 811s 9s/step - loss: 0.4757 - val_loss: 0.7137\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 814s 9s/step - loss: 0.4214 - val_loss: 0.7436\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 819s 10s/step - loss: 0.3677 - val_loss: 0.7897\n",
            "training model for CV #5\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 793s 9s/step - loss: 1.4421 - val_loss: 1.1720\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 833s 10s/step - loss: 1.0437 - val_loss: 0.9857\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 828s 10s/step - loss: 0.8790 - val_loss: 0.8782\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 829s 10s/step - loss: 0.7727 - val_loss: 0.8123\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 828s 10s/step - loss: 0.6891 - val_loss: 0.7920\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 830s 10s/step - loss: 0.6195 - val_loss: 0.7634\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 834s 10s/step - loss: 0.5772 - val_loss: 0.7692\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 836s 10s/step - loss: 0.5118 - val_loss: 0.7766\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.4540Restoring model weights from the end of the best epoch.\n",
            "86/86 [==============================] - 836s 10s/step - loss: 0.4540 - val_loss: 0.8011\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmwQlEgD_LG6",
        "outputId": "89b1dfd4-6d5f-45a8-d033-fd133d8b0603"
      },
      "source": [
        "print(clf.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 473, 100)          4233000   \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 473, 128)          84480     \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 4,416,941\n",
            "Trainable params: 183,941\n",
            "Non-trainable params: 4,233,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "F3yjoo8p-__D",
        "outputId": "c56d1dfc-8907-4c4c-afb4-56b49c32ba91"
      },
      "source": [
        "glove = pd.read_csv(\"/content/drive/MyDrive/소설작가분류/sample_submission.csv\", index_col=0)\n",
        "print(glove.shape)\n",
        "glove.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19617, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  1  2  3  4\n",
              "index               \n",
              "0      0  0  0  0  0\n",
              "1      0  0  0  0  0\n",
              "2      0  0  0  0  0\n",
              "3      0  0  0  0  0\n",
              "4      0  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "uJtPctBs_Ary",
        "outputId": "fae5d071-df58-46d0-f56f-1ac2f795314a"
      },
      "source": [
        "glove[glove.columns] = p_tst\n",
        "glove.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.030622</td>\n",
              "      <td>0.512434</td>\n",
              "      <td>0.137687</td>\n",
              "      <td>0.318001</td>\n",
              "      <td>0.001257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.095761</td>\n",
              "      <td>0.532137</td>\n",
              "      <td>0.021741</td>\n",
              "      <td>0.334997</td>\n",
              "      <td>0.015363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.934131</td>\n",
              "      <td>0.009992</td>\n",
              "      <td>0.009206</td>\n",
              "      <td>0.008183</td>\n",
              "      <td>0.038488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000939</td>\n",
              "      <td>0.014082</td>\n",
              "      <td>0.981871</td>\n",
              "      <td>0.000552</td>\n",
              "      <td>0.002556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.881813</td>\n",
              "      <td>0.035733</td>\n",
              "      <td>0.018257</td>\n",
              "      <td>0.027389</td>\n",
              "      <td>0.036808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2         3         4\n",
              "index                                                  \n",
              "0      0.030622  0.512434  0.137687  0.318001  0.001257\n",
              "1      0.095761  0.532137  0.021741  0.334997  0.015363\n",
              "2      0.934131  0.009992  0.009206  0.008183  0.038488\n",
              "3      0.000939  0.014082  0.981871  0.000552  0.002556\n",
              "4      0.881813  0.035733  0.018257  0.027389  0.036808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCw3dvjc_D6w"
      },
      "source": [
        "glove.to_csv(\"glove.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwyydwCc-cJh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}